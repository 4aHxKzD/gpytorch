{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPyTorch Regression Tutorial\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we demonstrate many of the design features of GPyTorch using the simplest example, training an RBF kernel Gaussian process on a simple function. We'll be modeling the function\n",
    "\n",
    "\\begin{align}\n",
    "y &= \\sin(2\\pi x) + \\epsilon \\\\\n",
    "  \\epsilon &\\sim \\mathcal{N}(0, 0.04) \n",
    "\\end{align}\n",
    "\n",
    "with 100 training examples, and testing on 51 test examples.\n",
    "\n",
    "**Note:** this notebook is not necessarily intended to teach the mathematical background of Gaussian processes, but rather how to train a simple one and make predictions in GPyTorch. For a mathematical treatment, Chapter 2 of Gaussian Processes for Machine Learning provides a very thorough introduction to GP regression (this entire text is highly recommended): http://www.gaussianprocess.org/gpml/chapters/RW2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training data\n",
    "\n",
    "In the next cell, we set up the training data for this example. We'll be using 100 regularly spaced points on [0,1] which we evaluate the function on and add Gaussian noise to get the training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0., 3., 15)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x / 3. * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "\n",
    "The next cell demonstrates the most critical features of a user-defined Gaussian process model in GPyTorch. Building a GP model in GPyTorch is different in a number of ways.\n",
    "\n",
    "First in contrast to many existing GP packages, we do not provide full GP models for the user. Rather, we provide *the tools necessary to quickly construct one*. This is because we believe, analogous to building a neural network in standard PyTorch, it is important to have the flexibility to include whatever components are necessary. As can be seen in more complicated examples, this allows the user great flexibility in designing custom models.\n",
    "\n",
    "For most GP regression models, you will need to construct the following GPyTorch objects:\n",
    "\n",
    "1. A **GP Model** (`gpytorch.models.ExactGP`) -  This handles most of the inference.\n",
    "1. A **Likelihood** (`gpytorch.likelihoods.GaussianLikelihood`) - This is the most common likelihood used for GP regression.\n",
    "1. A **Mean** - This defines the prior mean of the GP.(If you don't know which mean to use, a `gpytorch.means.ConstantMean()` is a good place to start.)\n",
    "1. A **Kernel** - This defines the prior covariance of the GP.(If you don't know which kernel to use, a `gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())` is a good place to start).\n",
    "1. A **MultivariateNormal** Distribution (`gpytorch.distributions.MultivariateNormal`) - This is the object used to represent multivariate normal distributions.\n",
    "  \n",
    "  \n",
    "### The GP Model\n",
    "  \n",
    "The components of a user built (Exact, i.e. non-variational) GP model in GPyTorch are, broadly speaking:\n",
    "\n",
    "1. An `__init__` method that takes the training data and a likelihood, and constructs whatever objects are necessary for the model's `forward` method. This will most commonly include things like a mean module and a kernel module.\n",
    "\n",
    "2. A `forward` method that takes in some $n \\times d$ data `x` and returns a `MultivariateNormal` with the *prior* mean and covariance evaluated at `x`. In other words, we return the vector $\\mu(x)$ and the $n \\times n$ matrix $K_{xx}$ representing the prior mean and covariance matrix of the GP. \n",
    "\n",
    "This specification leaves a large amount of flexibility when defining a model. For example, to compose two kernels via addition, you can either add the kernel modules directly:\n",
    "\n",
    "```python\n",
    "self.covar_module = ScaleKernel(RBFKernel() + WhiteNoiseKernel())\n",
    "```\n",
    "\n",
    "Or you can add the outputs of the kernel in the forward method:\n",
    "\n",
    "```python\n",
    "covar_x = self.rbf_kernel_module(x) + self.white_noise_module(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.WLSHKernel(num_samples=100, num_dims=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model modes\n",
    "\n",
    "Like most PyTorch modules, the `ExactGP` has a `.train()` and `.eval()` mode.\n",
    "- `.train()` mode is for optimizing model hyperameters.\n",
    "- `.eval()` mode is for computing predictions through the model posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "In the next cell, we handle using Type-II MLE to train the hyperparameters of the Gaussian process.\n",
    "\n",
    "The most obvious difference here compared to many other GP implementations is that, as in standard PyTorch, the core training loop is written by the user. In GPyTorch, we make use of the standard PyTorch optimizers as from `torch.optim`, and all trainable parameters of the model should be of type `torch.nn.Parameter`. Because GP models directly extend `torch.nn.Module`, calls to methods like `model.parameters()` or `model.named_parameters()` function as you might expect coming from PyTorch.\n",
    "\n",
    "In most cases, the boilerplate code below will work well. It has the same basic components as the standard PyTorch training loop:\n",
    "\n",
    "1. Zero all parameter gradients\n",
    "2. Call the model and compute the loss\n",
    "3. Call backward on the loss to fill in gradients\n",
    "4. Take a step on the optimizer\n",
    "\n",
    "However, defining custom training loops allows for greater flexibility. For example, it is easy to save the parameters at each step of training, or use different learning rates for different parameters (which may be useful in deep kernel learning for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 1.044   lengthscale: 0.693   os: 0.693    noise: 0.693\n",
      "Iter 2/50 - Loss: 1.062   lengthscale: 0.644   os: 0.644    noise: 0.644\n",
      "Iter 3/50 - Loss: 0.937   lengthscale: 0.605   os: 0.598    noise: 0.598\n",
      "Iter 4/50 - Loss: 0.965   lengthscale: 0.609   os: 0.561    noise: 0.554\n",
      "Iter 5/50 - Loss: 0.925   lengthscale: 0.627   os: 0.524    noise: 0.513\n",
      "Iter 6/50 - Loss: 0.871   lengthscale: 0.654   os: 0.491    noise: 0.474\n",
      "Iter 7/50 - Loss: 0.869   lengthscale: 0.678   os: 0.464    noise: 0.437\n",
      "Iter 8/50 - Loss: 0.827   lengthscale: 0.677   os: 0.442    noise: 0.403\n",
      "Iter 9/50 - Loss: 0.839   lengthscale: 0.663   os: 0.425    noise: 0.371\n",
      "Iter 10/50 - Loss: 0.796   lengthscale: 0.639   os: 0.412    noise: 0.341\n",
      "Iter 11/50 - Loss: 0.759   lengthscale: 0.614   os: 0.407    noise: 0.313\n",
      "Iter 12/50 - Loss: 0.789   lengthscale: 0.599   os: 0.407    noise: 0.287\n",
      "Iter 13/50 - Loss: 0.767   lengthscale: 0.584   os: 0.410    noise: 0.264\n",
      "Iter 14/50 - Loss: 0.723   lengthscale: 0.570   os: 0.415    noise: 0.242\n",
      "Iter 15/50 - Loss: 0.676   lengthscale: 0.556   os: 0.423    noise: 0.222\n",
      "Iter 16/50 - Loss: 0.655   lengthscale: 0.538   os: 0.436    noise: 0.203\n",
      "Iter 17/50 - Loss: 0.615   lengthscale: 0.514   os: 0.455    noise: 0.186\n",
      "Iter 18/50 - Loss: 0.616   lengthscale: 0.487   os: 0.478    noise: 0.170\n",
      "Iter 19/50 - Loss: 0.597   lengthscale: 0.457   os: 0.502    noise: 0.155\n",
      "Iter 20/50 - Loss: 0.537   lengthscale: 0.427   os: 0.525    noise: 0.142\n",
      "Iter 21/50 - Loss: 0.637   lengthscale: 0.399   os: 0.543    noise: 0.129\n",
      "Iter 22/50 - Loss: 0.477   lengthscale: 0.380   os: 0.550    noise: 0.118\n",
      "Iter 23/50 - Loss: 0.460   lengthscale: 0.372   os: 0.550    noise: 0.108\n",
      "Iter 24/50 - Loss: 0.443   lengthscale: 0.371   os: 0.546    noise: 0.098\n",
      "Iter 25/50 - Loss: 0.416   lengthscale: 0.378   os: 0.538    noise: 0.090\n",
      "Iter 26/50 - Loss: 0.481   lengthscale: 0.390   os: 0.529    noise: 0.082\n",
      "Iter 27/50 - Loss: 0.379   lengthscale: 0.400   os: 0.514    noise: 0.074\n",
      "Iter 28/50 - Loss: 0.356   lengthscale: 0.411   os: 0.499    noise: 0.068\n",
      "Iter 29/50 - Loss: 0.400   lengthscale: 0.424   os: 0.487    noise: 0.062\n",
      "Iter 30/50 - Loss: 0.381   lengthscale: 0.436   os: 0.477    noise: 0.057\n",
      "Iter 31/50 - Loss: 0.306   lengthscale: 0.447   os: 0.471    noise: 0.052\n",
      "Iter 32/50 - Loss: 0.351   lengthscale: 0.448   os: 0.471    noise: 0.047\n",
      "Iter 33/50 - Loss: 0.326   lengthscale: 0.440   os: 0.477    noise: 0.043\n",
      "Iter 34/50 - Loss: 0.254   lengthscale: 0.437   os: 0.485    noise: 0.040\n",
      "Iter 35/50 - Loss: 0.227   lengthscale: 0.429   os: 0.499    noise: 0.037\n",
      "Iter 36/50 - Loss: 0.366   lengthscale: 0.416   os: 0.516    noise: 0.034\n",
      "Iter 37/50 - Loss: 0.197   lengthscale: 0.401   os: 0.528    noise: 0.031\n",
      "Iter 38/50 - Loss: 0.345   lengthscale: 0.385   os: 0.539    noise: 0.029\n",
      "Iter 39/50 - Loss: 0.299   lengthscale: 0.370   os: 0.541    noise: 0.027\n",
      "Iter 40/50 - Loss: 0.276   lengthscale: 0.377   os: 0.538    noise: 0.025\n",
      "Iter 41/50 - Loss: 0.298   lengthscale: 0.388   os: 0.529    noise: 0.023\n",
      "Iter 42/50 - Loss: 0.268   lengthscale: 0.399   os: 0.515    noise: 0.021\n",
      "Iter 43/50 - Loss: 0.232   lengthscale: 0.405   os: 0.501    noise: 0.020\n",
      "Iter 44/50 - Loss: 0.373   lengthscale: 0.406   os: 0.489    noise: 0.019\n",
      "Iter 45/50 - Loss: 0.226   lengthscale: 0.401   os: 0.477    noise: 0.018\n",
      "Iter 46/50 - Loss: 0.187   lengthscale: 0.390   os: 0.469    noise: 0.016\n",
      "Iter 47/50 - Loss: 0.268   lengthscale: 0.380   os: 0.465    noise: 0.016\n",
      "Iter 48/50 - Loss: 0.254   lengthscale: 0.373   os: 0.460    noise: 0.015\n",
      "Iter 49/50 - Loss: 0.238   lengthscale: 0.372   os: 0.457    noise: 0.014\n",
      "Iter 50/50 - Loss: 0.315   lengthscale: 0.381   os: 0.455    noise: 0.013\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "with gpytorch.settings.max_cholesky_size(0), gpytorch.settings.lazily_evaluate_kernels(False):\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   os: %.3f    noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.base_kernel.lengthscale.item(),\n",
    "            model.covar_module.outputscale.item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2806, 0.2415, 0.1877, 0.1365, 0.1100, 0.0806, 0.0590, 0.0453, 0.0312,\n",
      "         0.0189, 0.0126, 0.0080, 0.0035, 0.0013, 0.0010],\n",
      "        [0.2415, 0.2957, 0.2604, 0.2092, 0.1667, 0.1258, 0.0947, 0.0710, 0.0461,\n",
      "         0.0268, 0.0186, 0.0125, 0.0061, 0.0029, 0.0025],\n",
      "        [0.1877, 0.2604, 0.3059, 0.2804, 0.2371, 0.1872, 0.1414, 0.1066, 0.0674,\n",
      "         0.0345, 0.0234, 0.0156, 0.0079, 0.0042, 0.0038],\n",
      "        [0.1365, 0.2092, 0.2804, 0.3397, 0.3092, 0.2568, 0.2015, 0.1559, 0.0993,\n",
      "         0.0512, 0.0326, 0.0195, 0.0094, 0.0056, 0.0052],\n",
      "        [0.1100, 0.1667, 0.2371, 0.3092, 0.3414, 0.3072, 0.2496, 0.2015, 0.1267,\n",
      "         0.0735, 0.0458, 0.0260, 0.0130, 0.0082, 0.0077],\n",
      "        [0.0806, 0.1258, 0.1872, 0.2568, 0.3072, 0.3426, 0.2993, 0.2506, 0.1580,\n",
      "         0.1029, 0.0678, 0.0414, 0.0211, 0.0119, 0.0110],\n",
      "        [0.0590, 0.0947, 0.1414, 0.2015, 0.2496, 0.2993, 0.3242, 0.2935, 0.1982,\n",
      "         0.1386, 0.0911, 0.0575, 0.0307, 0.0178, 0.0160],\n",
      "        [0.0453, 0.0710, 0.1066, 0.1559, 0.2015, 0.2506, 0.2935, 0.3242, 0.2499,\n",
      "         0.1908, 0.1338, 0.0911, 0.0537, 0.0339, 0.0286],\n",
      "        [0.0312, 0.0461, 0.0674, 0.0993, 0.1267, 0.1580, 0.1982, 0.2499, 0.2805,\n",
      "         0.2490, 0.1893, 0.1381, 0.0864, 0.0582, 0.0474],\n",
      "        [0.0189, 0.0268, 0.0345, 0.0512, 0.0735, 0.1029, 0.1386, 0.1908, 0.2490,\n",
      "         0.2926, 0.2542, 0.2015, 0.1329, 0.0911, 0.0700],\n",
      "        [0.0126, 0.0186, 0.0234, 0.0326, 0.0458, 0.0678, 0.0911, 0.1338, 0.1893,\n",
      "         0.2542, 0.2914, 0.2612, 0.1875, 0.1390, 0.1125],\n",
      "        [0.0080, 0.0125, 0.0156, 0.0195, 0.0260, 0.0414, 0.0575, 0.0911, 0.1381,\n",
      "         0.2015, 0.2612, 0.3009, 0.2558, 0.2088, 0.1759],\n",
      "        [0.0035, 0.0061, 0.0079, 0.0094, 0.0130, 0.0211, 0.0307, 0.0537, 0.0864,\n",
      "         0.1329, 0.1875, 0.2558, 0.2933, 0.2701, 0.2348],\n",
      "        [0.0013, 0.0029, 0.0042, 0.0056, 0.0082, 0.0119, 0.0178, 0.0339, 0.0582,\n",
      "         0.0911, 0.1390, 0.2088, 0.2701, 0.3236, 0.3062],\n",
      "        [0.0010, 0.0025, 0.0038, 0.0052, 0.0077, 0.0110, 0.0160, 0.0286, 0.0474,\n",
      "         0.0700, 0.1125, 0.1759, 0.2348, 0.3062, 0.3443]],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with gpytorch.settings.prior_mode(), gpytorch.settings.max_cholesky_size(0):\n",
    "    print(model(train_x).covariance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions with the model\n",
    "\n",
    "In the next cell, we make predictions with the model. To do this, we simply put the model and likelihood in eval mode, and call both modules on the test data.\n",
    "\n",
    "Just as a user defined GP model returns a `MultivariateNormal` containing the prior mean and covariance from forward, a trained GP model in eval mode returns a `MultivariateNormal` containing the posterior mean and covariance. Thus, getting the predictive mean and variance, and then sampling functions from the GP at the given test points could be accomplished with calls like:\n",
    "\n",
    "```python\n",
    "f_preds = model(test_x)\n",
    "y_preds = likelihood(model(test_x))\n",
    "\n",
    "f_mean = f_preds.mean\n",
    "f_var = f_preds.variance\n",
    "f_covar = f_preds.covariance_matrix\n",
    "f_samples = f_preds.sample(sample_shape=torch.Size(1000,))\n",
    "```\n",
    "\n",
    "The `gpytorch.settings.fast_pred_var` context is not needed, but here we are giving a preview of using one of our cool features, getting faster predictive distributions using [LOVE](https://arxiv.org/abs/1803.06058)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.max_cholesky_size(0):\n",
    "    with gpytorch.settings.lazily_evaluate_kernels(False):\n",
    "        test_x = torch.linspace(2, 6, 51)\n",
    "        observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the model fit\n",
    "\n",
    "In the next cell, we plot the mean and confidence region of the Gaussian process model. The `confidence_region` method is a helper method that returns 2 standard deviations above and below the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
