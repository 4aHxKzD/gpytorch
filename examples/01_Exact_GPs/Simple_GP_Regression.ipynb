{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPyTorch Regression Tutorial\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we demonstrate many of the design features of GPyTorch using the simplest example, training an RBF kernel Gaussian process on a simple function. We'll be modeling the function\n",
    "\n",
    "\\begin{align}\n",
    "y &= \\sin(2\\pi x) + \\epsilon \\\\\n",
    "  \\epsilon &\\sim \\mathcal{N}(0, 0.04) \n",
    "\\end{align}\n",
    "\n",
    "with 100 training examples, and testing on 51 test examples.\n",
    "\n",
    "**Note:** this notebook is not necessarily intended to teach the mathematical background of Gaussian processes, but rather how to train a simple one and make predictions in GPyTorch. For a mathematical treatment, Chapter 2 of Gaussian Processes for Machine Learning provides a very thorough introduction to GP regression (this entire text is highly recommended): http://www.gaussianprocess.org/gpml/chapters/RW2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training data\n",
    "\n",
    "In the next cell, we set up the training data for this example. We'll be using 100 regularly spaced points on [0,1] which we evaluate the function on and add Gaussian noise to get the training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 1000)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "\n",
    "The next cell demonstrates the most critical features of a user-defined Gaussian process model in GPyTorch. Building a GP model in GPyTorch is different in a number of ways.\n",
    "\n",
    "First in contrast to many existing GP packages, we do not provide full GP models for the user. Rather, we provide *the tools necessary to quickly construct one*. This is because we believe, analogous to building a neural network in standard PyTorch, it is important to have the flexibility to include whatever components are necessary. As can be seen in more complicated examples, this allows the user great flexibility in designing custom models.\n",
    "\n",
    "For most GP regression models, you will need to construct the following GPyTorch objects:\n",
    "\n",
    "1. A **GP Model** (`gpytorch.models.ExactGP`) -  This handles most of the inference.\n",
    "1. A **Likelihood** (`gpytorch.likelihoods.GaussianLikelihood`) - This is the most common likelihood used for GP regression.\n",
    "1. A **Mean** - This defines the prior mean of the GP.(If you don't know which mean to use, a `gpytorch.means.ConstantMean()` is a good place to start.)\n",
    "1. A **Kernel** - This defines the prior covariance of the GP.(If you don't know which kernel to use, a `gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())` is a good place to start).\n",
    "1. A **MultivariateNormal** Distribution (`gpytorch.distributions.MultivariateNormal`) - This is the object used to represent multivariate normal distributions.\n",
    "  \n",
    "  \n",
    "### The GP Model\n",
    "  \n",
    "The components of a user built (Exact, i.e. non-variational) GP model in GPyTorch are, broadly speaking:\n",
    "\n",
    "1. An `__init__` method that takes the training data and a likelihood, and constructs whatever objects are necessary for the model's `forward` method. This will most commonly include things like a mean module and a kernel module.\n",
    "\n",
    "2. A `forward` method that takes in some $n \\times d$ data `x` and returns a `MultivariateNormal` with the *prior* mean and covariance evaluated at `x`. In other words, we return the vector $\\mu(x)$ and the $n \\times n$ matrix $K_{xx}$ representing the prior mean and covariance matrix of the GP. \n",
    "\n",
    "This specification leaves a large amount of flexibility when defining a model. For example, to compose two kernels via addition, you can either add the kernel modules directly:\n",
    "\n",
    "```python\n",
    "self.covar_module = ScaleKernel(RBFKernel() + WhiteNoiseKernel())\n",
    "```\n",
    "\n",
    "Or you can add the outputs of the kernel in the forward method:\n",
    "\n",
    "```python\n",
    "covar_x = self.rbf_kernel_module(x) + self.white_noise_module(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        \n",
    "        assert 1 <= train_x.ndim <= 2\n",
    "        init_theta = (train_x[1:] - train_x[:-1]).norm(2, dim=-1).median()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "                                gpytorch.kernels.RBFKernel().initialize(lengthscale=init_theta)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model modes\n",
    "\n",
    "Like most PyTorch modules, the `ExactGP` has a `.train()` and `.eval()` mode.\n",
    "- `.train()` mode is for optimizing model hyperameters.\n",
    "- `.eval()` mode is for computing predictions through the model posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "In the next cell, we handle using Type-II MLE to train the hyperparameters of the Gaussian process.\n",
    "\n",
    "The most obvious difference here compared to many other GP implementations is that, as in standard PyTorch, the core training loop is written by the user. In GPyTorch, we make use of the standard PyTorch optimizers as from `torch.optim`, and all trainable parameters of the model should be of type `torch.nn.Parameter`. Because GP models directly extend `torch.nn.Module`, calls to methods like `model.parameters()` or `model.named_parameters()` function as you might expect coming from PyTorch.\n",
    "\n",
    "In most cases, the boilerplate code below will work well. It has the same basic components as the standard PyTorch training loop:\n",
    "\n",
    "1. Zero all parameter gradients\n",
    "2. Call the model and compute the loss\n",
    "3. Call backward on the loss to fill in gradients\n",
    "4. Take a step on the optimizer\n",
    "\n",
    "However, defining custom training loops allows for greater flexibility. For example, it is easy to save the parameters at each step of training, or use different learning rates for different parameters (which may be useful in deep kernel learning for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage1/Documents/repos/gpytorch/gpytorch/functions/_inv_quad_log_det.py:75: UserWarning: Deterministic probes will currently work only if you aren't training multiple independent models simultaneously.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance after 29 iterations: 6.755626236554235e-05\n",
      "Iter 1/50 - Loss: 0.951   lengthscale: 0.032   noise: 0.693\n",
      "Tolerance after 33 iterations: 7.581556565128267e-05\n",
      "Iter 2/50 - Loss: 0.954   lengthscale: 0.035   noise: 0.644\n",
      "Tolerance after 34 iterations: 4.6253317123046145e-05\n",
      "Iter 3/50 - Loss: 0.956   lengthscale: 0.039   noise: 0.598\n",
      "Tolerance after 33 iterations: 5.3785803174832836e-05\n",
      "Iter 4/50 - Loss: 0.958   lengthscale: 0.042   noise: 0.554\n",
      "Tolerance after 34 iterations: 5.8659978094510734e-05\n",
      "Iter 5/50 - Loss: 0.961   lengthscale: 0.047   noise: 0.513\n",
      "Tolerance after 32 iterations: 8.36625840747729e-05\n",
      "Iter 6/50 - Loss: 0.964   lengthscale: 0.052   noise: 0.474\n",
      "Tolerance after 33 iterations: 3.2756270229583606e-05\n",
      "Iter 7/50 - Loss: 0.968   lengthscale: 0.057   noise: 0.437\n",
      "Tolerance after 32 iterations: 3.594842564780265e-05\n",
      "Iter 8/50 - Loss: 0.972   lengthscale: 0.062   noise: 0.403\n",
      "Tolerance after 29 iterations: 4.928015187033452e-05\n",
      "Iter 9/50 - Loss: 0.976   lengthscale: 0.069   noise: 0.370\n",
      "Tolerance after 28 iterations: 5.124948802404106e-05\n",
      "Iter 10/50 - Loss: 0.981   lengthscale: 0.075   noise: 0.340\n",
      "Tolerance after 28 iterations: 2.993580164911691e-05\n",
      "Iter 11/50 - Loss: 0.986   lengthscale: 0.082   noise: 0.312\n",
      "Tolerance after 26 iterations: 6.833766383351758e-05\n",
      "Iter 12/50 - Loss: 0.992   lengthscale: 0.090   noise: 0.286\n",
      "Tolerance after 25 iterations: 7.140757952583954e-05\n",
      "Iter 13/50 - Loss: 0.998   lengthscale: 0.098   noise: 0.262\n",
      "Tolerance after 27 iterations: 1.2497066563810222e-05\n",
      "Iter 14/50 - Loss: 1.005   lengthscale: 0.106   noise: 0.240\n",
      "Tolerance after 26 iterations: 2.2965818061493337e-05\n",
      "Iter 15/50 - Loss: 1.013   lengthscale: 0.116   noise: 0.219\n",
      "Tolerance after 23 iterations: 3.923864642274566e-05\n",
      "Iter 16/50 - Loss: 1.022   lengthscale: 0.126   noise: 0.200\n",
      "Tolerance after 24 iterations: 2.51079945883248e-05\n",
      "Iter 17/50 - Loss: 1.032   lengthscale: 0.136   noise: 0.182\n",
      "Tolerance after 22 iterations: 3.607266990002245e-05\n",
      "Iter 18/50 - Loss: 1.043   lengthscale: 0.148   noise: 0.166\n",
      "Tolerance after 20 iterations: 4.950549191562459e-05\n",
      "Iter 19/50 - Loss: 1.055   lengthscale: 0.161   noise: 0.151\n",
      "Tolerance after 21 iterations: 8.567641089030076e-06\n",
      "Iter 20/50 - Loss: 1.068   lengthscale: 0.174   noise: 0.138\n",
      "Tolerance after 19 iterations: 4.520908623817377e-05\n",
      "Iter 21/50 - Loss: 1.082   lengthscale: 0.189   noise: 0.126\n",
      "Tolerance after 18 iterations: 3.3521897421451285e-05\n",
      "Iter 22/50 - Loss: 1.098   lengthscale: 0.204   noise: 0.115\n",
      "Tolerance after 19 iterations: 4.877227183897048e-05\n",
      "Iter 23/50 - Loss: 1.116   lengthscale: 0.220   noise: 0.104\n",
      "Tolerance after 20 iterations: 3.3026302844518796e-05\n",
      "Iter 24/50 - Loss: 1.135   lengthscale: 0.237   noise: 0.095\n",
      "Tolerance after 18 iterations: 1.858254472608678e-05\n",
      "Iter 25/50 - Loss: 1.156   lengthscale: 0.254   noise: 0.087\n",
      "Tolerance after 18 iterations: 3.7973815778968856e-05\n",
      "Iter 26/50 - Loss: 1.178   lengthscale: 0.270   noise: 0.079\n",
      "Tolerance after 19 iterations: 1.7279335224884562e-05\n",
      "Iter 27/50 - Loss: 1.202   lengthscale: 0.284   noise: 0.073\n",
      "Tolerance after 19 iterations: 4.171413365838816e-06\n",
      "Iter 28/50 - Loss: 1.227   lengthscale: 0.294   noise: 0.067\n",
      "Tolerance after 20 iterations: 8.022002475627232e-07\n",
      "Iter 29/50 - Loss: 1.253   lengthscale: 0.301   noise: 0.061\n",
      "Tolerance after 20 iterations: 3.434343307162635e-05\n",
      "Iter 30/50 - Loss: 1.280   lengthscale: 0.304   noise: 0.056\n",
      "Tolerance after 20 iterations: 3.9546397601952776e-05\n",
      "Iter 31/50 - Loss: 1.309   lengthscale: 0.305   noise: 0.052\n",
      "Tolerance after 20 iterations: 3.6980840377509594e-05\n",
      "Iter 32/50 - Loss: 1.338   lengthscale: 0.303   noise: 0.048\n",
      "Tolerance after 21 iterations: 4.498318503465271e-06\n",
      "Iter 33/50 - Loss: 1.367   lengthscale: 0.300   noise: 0.045\n",
      "Tolerance after 21 iterations: 1.3829930139763746e-05\n",
      "Iter 34/50 - Loss: 1.397   lengthscale: 0.297   noise: 0.042\n",
      "Tolerance after 20 iterations: 5.0033413572236896e-05\n",
      "Iter 35/50 - Loss: 1.427   lengthscale: 0.295   noise: 0.039\n",
      "Tolerance after 21 iterations: 1.1365356840542518e-05\n",
      "Iter 36/50 - Loss: 1.456   lengthscale: 0.294   noise: 0.037\n",
      "Tolerance after 21 iterations: 5.586394036072306e-05\n",
      "Iter 37/50 - Loss: 1.483   lengthscale: 0.296   noise: 0.035\n",
      "Tolerance after 21 iterations: 2.9394022931228392e-05\n",
      "Iter 38/50 - Loss: 1.508   lengthscale: 0.299   noise: 0.034\n",
      "Tolerance after 21 iterations: 3.678450229926966e-05\n",
      "Iter 39/50 - Loss: 1.530   lengthscale: 0.304   noise: 0.032\n",
      "Tolerance after 22 iterations: 3.1490410037804395e-05\n",
      "Iter 40/50 - Loss: 1.549   lengthscale: 0.312   noise: 0.032\n",
      "Tolerance after 23 iterations: 9.022105587064289e-06\n",
      "Iter 41/50 - Loss: 1.563   lengthscale: 0.321   noise: 0.031\n",
      "Tolerance after 23 iterations: 4.531285958364606e-05\n",
      "Iter 42/50 - Loss: 1.574   lengthscale: 0.331   noise: 0.030\n",
      "Tolerance after 24 iterations: 1.4414328688872047e-05\n",
      "Iter 43/50 - Loss: 1.580   lengthscale: 0.342   noise: 0.030\n",
      "Tolerance after 28 iterations: 1.5970354070304893e-05\n",
      "Iter 44/50 - Loss: 1.583   lengthscale: 0.353   noise: 0.030\n",
      "Tolerance after 19 iterations: 4.954518226440996e-05\n",
      "Iter 45/50 - Loss: 1.581   lengthscale: 0.362   noise: 0.030\n",
      "Tolerance after 19 iterations: 4.9404232413508e-05\n",
      "Iter 46/50 - Loss: 1.575   lengthscale: 0.370   noise: 0.030\n",
      "Tolerance after 25 iterations: 3.1825829864828847e-06\n",
      "Iter 47/50 - Loss: 1.567   lengthscale: 0.375   noise: 0.031\n",
      "Tolerance after 19 iterations: 6.544728967128322e-05\n",
      "Iter 48/50 - Loss: 1.556   lengthscale: 0.378   noise: 0.031\n",
      "Tolerance after 22 iterations: 5.237240111455321e-05\n",
      "Iter 49/50 - Loss: 1.543   lengthscale: 0.378   noise: 0.032\n",
      "Tolerance after 19 iterations: 5.1662311307154596e-05\n",
      "Iter 50/50 - Loss: 1.529   lengthscale: 0.376   noise: 0.033\n"
     ]
    }
   ],
   "source": [
    "training_iter = 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "with gpytorch.settings.skip_logdet_forward(), \\\n",
    "    gpytorch.settings.max_preconditioner_size(0), \\\n",
    "    gpytorch.settings.ir_solve(), \\\n",
    "    gpytorch.settings.cg_tolerance(1e-4), \\\n",
    "    gpytorch.settings.max_cg_iterations(1000), \\\n",
    "    gpytorch.settings.deterministic_probes(), \\\n",
    "    gpytorch.settings.num_trace_samples(1)\\\n",
    ":\n",
    "    \n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.base_kernel.lengthscale.item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions with the model\n",
    "\n",
    "In the next cell, we make predictions with the model. To do this, we simply put the model and likelihood in eval mode, and call both modules on the test data.\n",
    "\n",
    "Just as a user defined GP model returns a `MultivariateNormal` containing the prior mean and covariance from forward, a trained GP model in eval mode returns a `MultivariateNormal` containing the posterior mean and covariance. Thus, getting the predictive mean and variance, and then sampling functions from the GP at the given test points could be accomplished with calls like:\n",
    "\n",
    "```python\n",
    "f_preds = model(test_x)\n",
    "y_preds = likelihood(model(test_x))\n",
    "\n",
    "f_mean = f_preds.mean\n",
    "f_var = f_preds.variance\n",
    "f_covar = f_preds.covariance_matrix\n",
    "f_samples = f_preds.sample(sample_shape=torch.Size(1000,))\n",
    "```\n",
    "\n",
    "The `gpytorch.settings.fast_pred_var` context is not needed, but here we are giving a preview of using one of our cool features, getting faster predictive distributions using [LOVE](https://arxiv.org/abs/1803.06058)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance after 9 iterations: 0.009361078962683678\n"
     ]
    }
   ],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(0, 1, 51)\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the model fit\n",
    "\n",
    "In the next cell, we plot the mean and confidence region of the Gaussian process model. The `confidence_region` method is a helper method that returns 2 standard deviations above and below the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
