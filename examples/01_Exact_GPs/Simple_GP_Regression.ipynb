{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPyTorch Regression Tutorial\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we demonstrate many of the design features of GPyTorch using the simplest example, training an RBF kernel Gaussian process on a simple function. We'll be modeling the function\n",
    "\n",
    "\\begin{align}\n",
    "y &= \\sin(2\\pi x) + \\epsilon \\\\\n",
    "  \\epsilon &\\sim \\mathcal{N}(0, 0.04) \n",
    "\\end{align}\n",
    "\n",
    "with 100 training examples, and testing on 51 test examples.\n",
    "\n",
    "**Note:** this notebook is not necessarily intended to teach the mathematical background of Gaussian processes, but rather how to train a simple one and make predictions in GPyTorch. For a mathematical treatment, Chapter 2 of Gaussian Processes for Machine Learning provides a very thorough introduction to GP regression (this entire text is highly recommended): http://www.gaussianprocess.org/gpml/chapters/RW2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training data\n",
    "\n",
    "In the next cell, we set up the training data for this example. We'll be using 100 regularly spaced points on [0,1] which we evaluate the function on and add Gaussian noise to get the training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 1000)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "\n",
    "The next cell demonstrates the most critical features of a user-defined Gaussian process model in GPyTorch. Building a GP model in GPyTorch is different in a number of ways.\n",
    "\n",
    "First in contrast to many existing GP packages, we do not provide full GP models for the user. Rather, we provide *the tools necessary to quickly construct one*. This is because we believe, analogous to building a neural network in standard PyTorch, it is important to have the flexibility to include whatever components are necessary. As can be seen in more complicated examples, this allows the user great flexibility in designing custom models.\n",
    "\n",
    "For most GP regression models, you will need to construct the following GPyTorch objects:\n",
    "\n",
    "1. A **GP Model** (`gpytorch.models.ExactGP`) -  This handles most of the inference.\n",
    "1. A **Likelihood** (`gpytorch.likelihoods.GaussianLikelihood`) - This is the most common likelihood used for GP regression.\n",
    "1. A **Mean** - This defines the prior mean of the GP.(If you don't know which mean to use, a `gpytorch.means.ConstantMean()` is a good place to start.)\n",
    "1. A **Kernel** - This defines the prior covariance of the GP.(If you don't know which kernel to use, a `gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())` is a good place to start).\n",
    "1. A **MultivariateNormal** Distribution (`gpytorch.distributions.MultivariateNormal`) - This is the object used to represent multivariate normal distributions.\n",
    "  \n",
    "  \n",
    "### The GP Model\n",
    "  \n",
    "The components of a user built (Exact, i.e. non-variational) GP model in GPyTorch are, broadly speaking:\n",
    "\n",
    "1. An `__init__` method that takes the training data and a likelihood, and constructs whatever objects are necessary for the model's `forward` method. This will most commonly include things like a mean module and a kernel module.\n",
    "\n",
    "2. A `forward` method that takes in some $n \\times d$ data `x` and returns a `MultivariateNormal` with the *prior* mean and covariance evaluated at `x`. In other words, we return the vector $\\mu(x)$ and the $n \\times n$ matrix $K_{xx}$ representing the prior mean and covariance matrix of the GP. \n",
    "\n",
    "This specification leaves a large amount of flexibility when defining a model. For example, to compose two kernels via addition, you can either add the kernel modules directly:\n",
    "\n",
    "```python\n",
    "self.covar_module = ScaleKernel(RBFKernel() + WhiteNoiseKernel())\n",
    "```\n",
    "\n",
    "Or you can add the outputs of the kernel in the forward method:\n",
    "\n",
    "```python\n",
    "covar_x = self.rbf_kernel_module(x) + self.white_noise_module(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        \n",
    "        assert 1 <= train_x.ndim <= 2\n",
    "        init_theta = (train_x[1:] - train_x[:-1]).norm(2, dim=-1).median()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "                                gpytorch.kernels.RBFKernel().initialize(lengthscale=init_theta)\n",
    "        )\n",
    "        #self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "train_x = train_x.cuda()\n",
    "train_y = train_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.float()\n",
    "train_x = train_x.float()\n",
    "train_y = train_y.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model modes\n",
    "\n",
    "Like most PyTorch modules, the `ExactGP` has a `.train()` and `.eval()` mode.\n",
    "- `.train()` mode is for optimizing model hyperameters.\n",
    "- `.eval()` mode is for computing predictions through the model posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "In the next cell, we handle using Type-II MLE to train the hyperparameters of the Gaussian process.\n",
    "\n",
    "The most obvious difference here compared to many other GP implementations is that, as in standard PyTorch, the core training loop is written by the user. In GPyTorch, we make use of the standard PyTorch optimizers as from `torch.optim`, and all trainable parameters of the model should be of type `torch.nn.Parameter`. Because GP models directly extend `torch.nn.Module`, calls to methods like `model.parameters()` or `model.named_parameters()` function as you might expect coming from PyTorch.\n",
    "\n",
    "In most cases, the boilerplate code below will work well. It has the same basic components as the standard PyTorch training loop:\n",
    "\n",
    "1. Zero all parameter gradients\n",
    "2. Call the model and compute the loss\n",
    "3. Call backward on the loss to fill in gradients\n",
    "4. Take a step on the optimizer\n",
    "\n",
    "However, defining custom training loops allows for greater flexibility. For example, it is easy to save the parameters at each step of training, or use different learning rates for different parameters (which may be useful in deep kernel learning for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance after 3 iterations: 0.7683700323104858\n",
      "Iter 1/50 - Loss: 0.948   lengthscale: 0.032   noise: 0.693\n",
      "Tolerance after 1 iterations: 0.36358705163002014\n",
      "Iter 2/50 - Loss: 0.948   lengthscale: 0.035   noise: 0.644\n",
      "Tolerance after 1 iterations: 0.27448421716690063\n",
      "Iter 3/50 - Loss: 0.948   lengthscale: 0.038   noise: 0.598\n",
      "Tolerance after 1 iterations: 0.330593466758728\n",
      "Iter 4/50 - Loss: 0.948   lengthscale: 0.042   noise: 0.555\n",
      "Tolerance after 1 iterations: 0.37489232420921326\n",
      "Iter 5/50 - Loss: 0.948   lengthscale: 0.046   noise: 0.514\n",
      "Tolerance after 1 iterations: 0.4636271297931671\n",
      "Iter 6/50 - Loss: 0.949   lengthscale: 0.050   noise: 0.475\n",
      "Tolerance after 1 iterations: 0.4940192699432373\n",
      "Iter 7/50 - Loss: 0.949   lengthscale: 0.054   noise: 0.439\n",
      "Tolerance after 1 iterations: 0.5846624970436096\n",
      "Iter 8/50 - Loss: 0.949   lengthscale: 0.058   noise: 0.406\n",
      "Tolerance after 1 iterations: 0.5938591957092285\n",
      "Iter 9/50 - Loss: 0.949   lengthscale: 0.062   noise: 0.374\n",
      "Tolerance after 1 iterations: 0.6902255415916443\n",
      "Iter 10/50 - Loss: 0.950   lengthscale: 0.066   noise: 0.346\n",
      "Tolerance after 1 iterations: 0.6770548820495605\n",
      "Iter 11/50 - Loss: 0.950   lengthscale: 0.070   noise: 0.319\n",
      "Tolerance after 1 iterations: 0.783117949962616\n",
      "Iter 12/50 - Loss: 0.951   lengthscale: 0.074   noise: 0.294\n",
      "Tolerance after 1 iterations: 0.7466098070144653\n",
      "Iter 13/50 - Loss: 0.951   lengthscale: 0.078   noise: 0.272\n",
      "Tolerance after 1 iterations: 0.8650703430175781\n",
      "Iter 14/50 - Loss: 0.952   lengthscale: 0.082   noise: 0.251\n",
      "Tolerance after 1 iterations: 0.805415689945221\n",
      "Iter 15/50 - Loss: 0.951   lengthscale: 0.086   noise: 0.232\n",
      "Tolerance after 3 iterations: 0.5306154489517212\n",
      "Iter 16/50 - Loss: 1.007   lengthscale: 0.090   noise: 0.214\n",
      "Tolerance after 1 iterations: 0.4506012797355652\n",
      "Iter 17/50 - Loss: 1.008   lengthscale: 0.095   noise: 0.197\n",
      "Tolerance after 1 iterations: 0.2998805046081543\n",
      "Iter 18/50 - Loss: 1.007   lengthscale: 0.101   noise: 0.181\n",
      "Tolerance after 1 iterations: 0.4263605773448944\n",
      "Iter 19/50 - Loss: 1.008   lengthscale: 0.107   noise: 0.165\n",
      "Tolerance after 1 iterations: 0.3985641896724701\n",
      "Iter 20/50 - Loss: 1.007   lengthscale: 0.113   noise: 0.151\n",
      "Tolerance after 1 iterations: 0.5875564813613892\n",
      "Iter 21/50 - Loss: 1.008   lengthscale: 0.120   noise: 0.138\n",
      "Tolerance after 1 iterations: 0.5284652709960938\n",
      "Iter 22/50 - Loss: 1.008   lengthscale: 0.126   noise: 0.126\n",
      "Tolerance after 6 iterations: 0.49196910858154297\n",
      "Iter 23/50 - Loss: 1.089   lengthscale: 0.133   noise: 0.114\n",
      "Tolerance after 1 iterations: 0.25982728600502014\n",
      "Iter 24/50 - Loss: 1.088   lengthscale: 0.140   noise: 0.104\n",
      "Tolerance after 1 iterations: 0.35061532258987427\n",
      "Iter 25/50 - Loss: 1.088   lengthscale: 0.147   noise: 0.095\n",
      "Tolerance after 1 iterations: 0.36296311020851135\n",
      "Iter 26/50 - Loss: 1.089   lengthscale: 0.155   noise: 0.086\n",
      "Tolerance after 1 iterations: 0.5270442962646484\n",
      "Iter 27/50 - Loss: 1.089   lengthscale: 0.162   noise: 0.078\n",
      "Tolerance after 1 iterations: 0.5081257820129395\n",
      "Iter 28/50 - Loss: 1.089   lengthscale: 0.170   noise: 0.071\n",
      "Tolerance after 1 iterations: 0.6386035084724426\n",
      "Iter 29/50 - Loss: 1.089   lengthscale: 0.178   noise: 0.065\n",
      "Tolerance after 1 iterations: 0.6227372884750366\n",
      "Iter 30/50 - Loss: 1.090   lengthscale: 0.185   noise: 0.059\n",
      "Tolerance after 1 iterations: 0.7633576393127441\n",
      "Iter 31/50 - Loss: 1.090   lengthscale: 0.193   noise: 0.054\n",
      "Tolerance after 1 iterations: 0.7216443419456482\n",
      "Iter 32/50 - Loss: 1.090   lengthscale: 0.200   noise: 0.049\n",
      "Tolerance after 7 iterations: 0.42459410429000854\n",
      "Iter 33/50 - Loss: 1.352   lengthscale: 0.207   noise: 0.045\n",
      "Tolerance after 1 iterations: 0.13413366675376892\n",
      "Iter 34/50 - Loss: 1.352   lengthscale: 0.213   noise: 0.042\n",
      "Tolerance after 1 iterations: 0.5733842849731445\n",
      "Iter 35/50 - Loss: 1.352   lengthscale: 0.220   noise: 0.039\n",
      "Tolerance after 1 iterations: 0.26479223370552063\n",
      "Iter 36/50 - Loss: 1.353   lengthscale: 0.227   noise: 0.036\n",
      "Tolerance after 1 iterations: 0.5820097923278809\n",
      "Iter 37/50 - Loss: 1.353   lengthscale: 0.233   noise: 0.034\n",
      "Tolerance after 1 iterations: 0.3558592200279236\n",
      "Iter 38/50 - Loss: 1.353   lengthscale: 0.238   noise: 0.032\n",
      "Tolerance after 6 iterations: 0.3893575370311737\n",
      "Iter 39/50 - Loss: 1.527   lengthscale: 0.244   noise: 0.030\n",
      "Tolerance after 4 iterations: 0.39949148893356323\n",
      "Iter 40/50 - Loss: 1.526   lengthscale: 0.241   noise: 0.028\n",
      "Tolerance after 1 iterations: 0.3355013132095337\n",
      "Iter 41/50 - Loss: 1.526   lengthscale: 0.238   noise: 0.027\n",
      "Tolerance after 1 iterations: 0.4377315044403076\n",
      "Iter 42/50 - Loss: 1.526   lengthscale: 0.234   noise: 0.026\n",
      "Tolerance after 1 iterations: 0.389479398727417\n",
      "Iter 43/50 - Loss: 1.525   lengthscale: 0.231   noise: 0.025\n",
      "Tolerance after 1 iterations: 0.4451322555541992\n",
      "Iter 44/50 - Loss: 1.525   lengthscale: 0.228   noise: 0.025\n",
      "Tolerance after 1 iterations: 0.44587263464927673\n",
      "Iter 45/50 - Loss: 1.525   lengthscale: 0.224   noise: 0.024\n",
      "Tolerance after 8 iterations: 0.2932177186012268\n",
      "Iter 46/50 - Loss: 1.744   lengthscale: 0.221   noise: 0.024\n",
      "Tolerance after 3 iterations: 0.5158430337905884\n",
      "Iter 47/50 - Loss: 1.744   lengthscale: 0.219   noise: 0.024\n",
      "Tolerance after 1 iterations: 0.4790005683898926\n",
      "Iter 48/50 - Loss: 1.744   lengthscale: 0.217   noise: 0.024\n",
      "Tolerance after 1 iterations: 0.4298529326915741\n",
      "Iter 49/50 - Loss: 1.744   lengthscale: 0.215   noise: 0.025\n",
      "Tolerance after 1 iterations: 0.4304487705230713\n",
      "Iter 50/50 - Loss: 1.744   lengthscale: 0.213   noise: 0.026\n"
     ]
    }
   ],
   "source": [
    "training_iter = 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "with gpytorch.settings.skip_logdet_forward(), \\\n",
    "    gpytorch.settings.max_preconditioner_size(0), \\\n",
    "    gpytorch.settings.cg_tolerance(1), \\\n",
    "    gpytorch.settings.ir_solve(), \\\n",
    "    gpytorch.settings.max_cg_iterations(len(train_y)), \\\n",
    "    gpytorch.settings.deterministic_probes(), \\\n",
    "    gpytorch.settings.num_trace_samples(10)\\\n",
    ":\n",
    "    \n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.base_kernel.lengthscale.item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance after 13 iterations: 1.376132217956183e-06\n",
      "Iter 1/50 - Loss: 0.962   lengthscale: 0.473   noise: 0.857\n",
      "Before IR: tensor([ 0.0782,  0.0702,  0.0691,  0.0683,  0.1086,  0.0824,  0.0703,  0.0692,\n",
      "         0.0724,  0.0687, 15.6871], device='cuda:0')\n",
      "Tolerance after 5 iterations: 0.004323991015553474\n",
      "After IR: tensor(107532.3594, device='cuda:0')\n",
      "Iter 2/50 - Loss: 7.243   lengthscale: 0.436   noise: 0.800\n",
      "Before IR: tensor([2.6798e+00, 1.2863e+01, 4.4272e+01, 9.2660e+00, 2.0878e+01, 1.0669e+01,\n",
      "        1.0872e+01, 2.1801e+01, 3.1354e+01, 1.5151e+01, 1.1955e+05],\n",
      "       device='cuda:0')\n",
      "Tolerance after 11 iterations: 0.0002846813586074859\n",
      "After IR: tensor(2680916., device='cuda:0')\n",
      "Iter 3/50 - Loss: -140.044   lengthscale: 0.410   noise: 0.842\n",
      "Before IR: tensor([9.6269e-02, 6.5979e-02, 5.1207e-02, 5.4204e-02, 1.9353e-01, 1.2475e-01,\n",
      "        6.4391e-02, 5.3095e-02, 8.3932e-02, 5.7248e-02, 2.9240e+06],\n",
      "       device='cuda:0')\n",
      "Tolerance after 13 iterations: 0.0002716925519052893\n",
      "After IR: tensor(68638008., device='cuda:0')\n",
      "Iter 4/50 - Loss: 3311.272   lengthscale: 0.389   noise: 0.879\n",
      "Before IR: tensor([2.8745e+00, 1.3030e+01, 4.5657e+01, 9.4690e+00, 2.4659e+01, 1.1257e+01,\n",
      "        1.2461e+01, 2.2756e+01, 3.2032e+01, 1.5460e+01, 7.3997e+07],\n",
      "       device='cuda:0')\n",
      "Tolerance after 15 iterations: 0.0003011031949426979\n",
      "After IR: tensor(1.7336e+09, device='cuda:0')\n",
      "Iter 5/50 - Loss: -77563.852   lengthscale: 0.371   noise: 0.913\n",
      "Before IR: tensor([1.4904e-01, 1.0780e-01, 7.6323e-02, 8.0706e-02, 3.1577e-01, 2.2286e-01,\n",
      "        1.0218e-01, 7.8199e-02, 1.4997e-01, 9.2542e-02, 1.8540e+09],\n",
      "       device='cuda:0')\n",
      "Tolerance after 16 iterations: 0.004741679411381483\n",
      "After IR: tensor(4.3440e+10, device='cuda:0')\n",
      "Iter 6/50 - Loss: 1817591.750   lengthscale: 0.354   noise: 0.946\n",
      "Before IR: tensor([3.1402e+00, 1.3186e+01, 4.6593e+01, 9.6379e+00, 2.8162e+01, 1.1768e+01,\n",
      "        1.3899e+01, 2.3500e+01, 3.2416e+01, 1.5637e+01, 4.6176e+10],\n",
      "       device='cuda:0')\n",
      "Tolerance after 22 iterations: 0.0004787368234246969\n",
      "After IR: tensor(1.0819e+12, device='cuda:0')\n",
      "Iter 7/50 - Loss: -42591768.000   lengthscale: 0.339   noise: 0.978\n",
      "Before IR: tensor([2.1756e-01, 1.7835e-01, 1.3289e-01, 1.3684e-01, 4.6575e-01, 3.6639e-01,\n",
      "        1.6532e-01, 1.2930e-01, 2.5465e-01, 1.5788e-01, 1.1444e+12],\n",
      "       device='cuda:0')\n",
      "Tolerance after 23 iterations: 0.005196717567741871\n",
      "After IR: tensor(2.6814e+13, device='cuda:0')\n",
      "Iter 8/50 - Loss: 998057024.000   lengthscale: 0.325   noise: 1.010\n",
      "Before IR: tensor([3.3930e+00, 1.3648e+01, 4.8261e+01, 9.9957e+00, 3.0696e+01, 1.2348e+01,\n",
      "        1.4994e+01, 2.4488e+01, 3.3444e+01, 1.6133e+01, 2.7572e+13],\n",
      "       device='cuda:0')\n",
      "Tolerance after 27 iterations: 0.0011659851297736168\n",
      "After IR: tensor(6.4603e+14, device='cuda:0')\n",
      "Iter 9/50 - Loss: -23387568128.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([2.2371e-01, 1.8341e-01, 1.3667e-01, 1.4074e-01, 4.7889e-01, 3.7676e-01,\n",
      "        1.7003e-01, 1.3300e-01, 2.6190e-01, 1.6238e-01, 6.4611e+14],\n",
      "       device='cuda:0')\n",
      "Tolerance after 28 iterations: 0.002141625853255391\n",
      "After IR: tensor(1.5139e+16, device='cuda:0')\n",
      "Iter 10/50 - Loss: 548043227136.000   lengthscale: 0.325   noise: 1.042\n",
      "Tolerance after 15 iterations: 1.8207108496426372e-06\n",
      "Iter 11/50 - Loss: 0.941   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([8.5730e-06, 8.3093e-06, 1.0831e-05, 9.1375e-06, 7.0759e-06, 8.2961e-06,\n",
      "        7.4395e-06, 1.3503e-05, 8.3291e-06, 6.9891e-06, 1.4471e-04],\n",
      "       device='cuda:0')\n",
      "Tolerance after 1 iterations: 4.7830966650508344e-05\n",
      "After IR: tensor(174880.5000, device='cuda:0')\n",
      "Iter 12/50 - Loss: 7.353   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5549e+00, 1.3685e+01, 4.8302e+01, 9.9072e+00, 3.1124e+01, 1.2430e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6133e+01, 1.7488e+05],\n",
      "       device='cuda:0')\n",
      "Tolerance after 10 iterations: 0.008768577128648758\n",
      "After IR: tensor(3922635.7500, device='cuda:0')\n",
      "Iter 13/50 - Loss: -142.881   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.1329e-04, 5.1304e-04, 8.0287e-03, 1.3397e-04, 1.2545e-04, 8.2827e-03,\n",
      "        1.7958e-04, 1.4677e-04, 1.1749e-03, 6.5039e-03, 3.9231e+06],\n",
      "       device='cuda:0')\n",
      "Tolerance after 13 iterations: 0.008363472297787666\n",
      "After IR: tensor(92094904., device='cuda:0')\n",
      "Iter 14/50 - Loss: 3377.555   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 9.2106e+07],\n",
      "       device='cuda:0')\n",
      "Tolerance after 15 iterations: 0.002984812716022134\n",
      "After IR: tensor(2.1579e+09, device='cuda:0')\n",
      "Iter 15/50 - Loss: -79117.164   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.1748e-04, 5.1490e-04, 8.0353e-03, 1.3382e-04, 1.5389e-04, 8.2845e-03,\n",
      "        1.7958e-04, 1.6051e-04, 1.1769e-03, 6.5037e-03, 2.1581e+09],\n",
      "       device='cuda:0')\n",
      "Tolerance after 21 iterations: 0.0003638629277702421\n",
      "After IR: tensor(5.0566e+10, device='cuda:0')\n",
      "Iter 16/50 - Loss: 1853989.875   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 5.0572e+10],\n",
      "       device='cuda:0')\n",
      "Tolerance after 21 iterations: 0.002153731882572174\n",
      "After IR: tensor(1.1849e+12, device='cuda:0')\n",
      "Iter 17/50 - Loss: -43444724.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.2524e-04, 5.1747e-04, 8.1474e-03, 1.3272e-04, 1.4510e-04, 8.2835e-03,\n",
      "        1.7958e-04, 1.6941e-04, 1.1772e-03, 6.5031e-03, 1.1851e+12],\n",
      "       device='cuda:0')\n",
      "Tolerance after 24 iterations: 0.004158767405897379\n",
      "After IR: tensor(2.7767e+13, device='cuda:0')\n",
      "Iter 18/50 - Loss: 1018045248.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 2.7770e+13],\n",
      "       device='cuda:0')\n",
      "Tolerance after 28 iterations: 0.0002069742331514135\n",
      "After IR: tensor(6.5066e+14, device='cuda:0')\n",
      "Iter 19/50 - Loss: -23855947776.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.2369e-04, 5.2363e-04, 8.1474e-03, 1.3121e-04, 1.4267e-04, 8.2873e-03,\n",
      "        1.7958e-04, 1.6989e-04, 1.1791e-03, 6.5027e-03, 6.5073e+14],\n",
      "       device='cuda:0')\n",
      "Tolerance after 30 iterations: 0.004137684591114521\n",
      "After IR: tensor(1.5247e+16, device='cuda:0')\n",
      "Iter 20/50 - Loss: 559019130880.000   lengthscale: 0.325   noise: 1.042\n",
      "Tolerance after 15 iterations: 1.8207108496426372e-06\n",
      "Iter 21/50 - Loss: 0.941   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([8.5730e-06, 8.3093e-06, 1.0831e-05, 9.1375e-06, 7.0759e-06, 8.2961e-06,\n",
      "        7.4395e-06, 1.3503e-05, 8.3291e-06, 6.9891e-06, 1.4471e-04],\n",
      "       device='cuda:0')\n",
      "Tolerance after 1 iterations: 4.7830966650508344e-05\n",
      "After IR: tensor(174880.5000, device='cuda:0')\n",
      "Iter 22/50 - Loss: 7.353   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5549e+00, 1.3685e+01, 4.8302e+01, 9.9072e+00, 3.1124e+01, 1.2430e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6133e+01, 1.7488e+05],\n",
      "       device='cuda:0')\n",
      "Tolerance after 10 iterations: 0.008768577128648758\n",
      "After IR: tensor(3922635.7500, device='cuda:0')\n",
      "Iter 23/50 - Loss: -142.881   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.1329e-04, 5.1304e-04, 8.0287e-03, 1.3397e-04, 1.2545e-04, 8.2827e-03,\n",
      "        1.7958e-04, 1.4677e-04, 1.1749e-03, 6.5039e-03, 3.9231e+06],\n",
      "       device='cuda:0')\n",
      "Tolerance after 13 iterations: 0.008363472297787666\n",
      "After IR: tensor(92094904., device='cuda:0')\n",
      "Iter 24/50 - Loss: 3377.555   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 9.2106e+07],\n",
      "       device='cuda:0')\n",
      "Tolerance after 15 iterations: 0.002984812716022134\n",
      "After IR: tensor(2.1579e+09, device='cuda:0')\n",
      "Iter 25/50 - Loss: -79117.164   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.1748e-04, 5.1490e-04, 8.0353e-03, 1.3382e-04, 1.5389e-04, 8.2845e-03,\n",
      "        1.7958e-04, 1.6051e-04, 1.1769e-03, 6.5037e-03, 2.1581e+09],\n",
      "       device='cuda:0')\n",
      "Tolerance after 21 iterations: 0.0003638629277702421\n",
      "After IR: tensor(5.0566e+10, device='cuda:0')\n",
      "Iter 26/50 - Loss: 1853989.875   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 5.0572e+10],\n",
      "       device='cuda:0')\n",
      "Tolerance after 21 iterations: 0.002153731882572174\n",
      "After IR: tensor(1.1849e+12, device='cuda:0')\n",
      "Iter 27/50 - Loss: -43444724.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.2524e-04, 5.1747e-04, 8.1474e-03, 1.3272e-04, 1.4510e-04, 8.2835e-03,\n",
      "        1.7958e-04, 1.6941e-04, 1.1772e-03, 6.5031e-03, 1.1851e+12],\n",
      "       device='cuda:0')\n",
      "Tolerance after 24 iterations: 0.004158767405897379\n",
      "After IR: tensor(2.7767e+13, device='cuda:0')\n",
      "Iter 28/50 - Loss: 1018045248.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 2.7770e+13],\n",
      "       device='cuda:0')\n",
      "Tolerance after 28 iterations: 0.0002069742331514135\n",
      "After IR: tensor(6.5066e+14, device='cuda:0')\n",
      "Iter 29/50 - Loss: -23855947776.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.2369e-04, 5.2363e-04, 8.1474e-03, 1.3121e-04, 1.4267e-04, 8.2873e-03,\n",
      "        1.7958e-04, 1.6989e-04, 1.1791e-03, 6.5027e-03, 6.5073e+14],\n",
      "       device='cuda:0')\n",
      "Tolerance after 30 iterations: 0.004137684591114521\n",
      "After IR: tensor(1.5247e+16, device='cuda:0')\n",
      "Iter 30/50 - Loss: 559019130880.000   lengthscale: 0.325   noise: 1.042\n",
      "Tolerance after 15 iterations: 1.8207108496426372e-06\n",
      "Iter 31/50 - Loss: 0.941   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([8.5730e-06, 8.3093e-06, 1.0831e-05, 9.1375e-06, 7.0759e-06, 8.2961e-06,\n",
      "        7.4395e-06, 1.3503e-05, 8.3291e-06, 6.9891e-06, 1.4471e-04],\n",
      "       device='cuda:0')\n",
      "Tolerance after 1 iterations: 4.7830966650508344e-05\n",
      "After IR: tensor(174880.5000, device='cuda:0')\n",
      "Iter 32/50 - Loss: 7.353   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5549e+00, 1.3685e+01, 4.8302e+01, 9.9072e+00, 3.1124e+01, 1.2430e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6133e+01, 1.7488e+05],\n",
      "       device='cuda:0')\n",
      "Tolerance after 10 iterations: 0.008768577128648758\n",
      "After IR: tensor(3922635.7500, device='cuda:0')\n",
      "Iter 33/50 - Loss: -142.881   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.1329e-04, 5.1304e-04, 8.0287e-03, 1.3397e-04, 1.2545e-04, 8.2827e-03,\n",
      "        1.7958e-04, 1.4677e-04, 1.1749e-03, 6.5039e-03, 3.9231e+06],\n",
      "       device='cuda:0')\n",
      "Tolerance after 13 iterations: 0.008363472297787666\n",
      "After IR: tensor(92094904., device='cuda:0')\n",
      "Iter 34/50 - Loss: 3377.555   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 9.2106e+07],\n",
      "       device='cuda:0')\n",
      "Tolerance after 15 iterations: 0.002984812716022134\n",
      "After IR: tensor(2.1579e+09, device='cuda:0')\n",
      "Iter 35/50 - Loss: -79117.164   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.1748e-04, 5.1490e-04, 8.0353e-03, 1.3382e-04, 1.5389e-04, 8.2845e-03,\n",
      "        1.7958e-04, 1.6051e-04, 1.1769e-03, 6.5037e-03, 2.1581e+09],\n",
      "       device='cuda:0')\n",
      "Tolerance after 21 iterations: 0.0003638629277702421\n",
      "After IR: tensor(5.0566e+10, device='cuda:0')\n",
      "Iter 36/50 - Loss: 1853989.875   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 5.0572e+10],\n",
      "       device='cuda:0')\n",
      "Tolerance after 21 iterations: 0.002153731882572174\n",
      "After IR: tensor(1.1849e+12, device='cuda:0')\n",
      "Iter 37/50 - Loss: -43444724.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.2524e-04, 5.1747e-04, 8.1474e-03, 1.3272e-04, 1.4510e-04, 8.2835e-03,\n",
      "        1.7958e-04, 1.6941e-04, 1.1772e-03, 6.5031e-03, 1.1851e+12],\n",
      "       device='cuda:0')\n",
      "Tolerance after 24 iterations: 0.004158767405897379\n",
      "After IR: tensor(2.7767e+13, device='cuda:0')\n",
      "Iter 38/50 - Loss: 1018045248.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 2.7770e+13],\n",
      "       device='cuda:0')\n",
      "Tolerance after 28 iterations: 0.0002069742331514135\n",
      "After IR: tensor(6.5066e+14, device='cuda:0')\n",
      "Iter 39/50 - Loss: -23855947776.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.2369e-04, 5.2363e-04, 8.1474e-03, 1.3121e-04, 1.4267e-04, 8.2873e-03,\n",
      "        1.7958e-04, 1.6989e-04, 1.1791e-03, 6.5027e-03, 6.5073e+14],\n",
      "       device='cuda:0')\n",
      "Tolerance after 30 iterations: 0.004137684591114521\n",
      "After IR: tensor(1.5247e+16, device='cuda:0')\n",
      "Iter 40/50 - Loss: 559019130880.000   lengthscale: 0.325   noise: 1.042\n",
      "Tolerance after 15 iterations: 1.8207108496426372e-06\n",
      "Iter 41/50 - Loss: 0.941   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([8.5730e-06, 8.3093e-06, 1.0831e-05, 9.1375e-06, 7.0759e-06, 8.2961e-06,\n",
      "        7.4395e-06, 1.3503e-05, 8.3291e-06, 6.9891e-06, 1.4471e-04],\n",
      "       device='cuda:0')\n",
      "Tolerance after 1 iterations: 4.7830966650508344e-05\n",
      "After IR: tensor(174880.5000, device='cuda:0')\n",
      "Iter 42/50 - Loss: 7.353   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5549e+00, 1.3685e+01, 4.8302e+01, 9.9072e+00, 3.1124e+01, 1.2430e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6133e+01, 1.7488e+05],\n",
      "       device='cuda:0')\n",
      "Tolerance after 10 iterations: 0.008768577128648758\n",
      "After IR: tensor(3922635.7500, device='cuda:0')\n",
      "Iter 43/50 - Loss: -142.881   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.1329e-04, 5.1304e-04, 8.0287e-03, 1.3397e-04, 1.2545e-04, 8.2827e-03,\n",
      "        1.7958e-04, 1.4677e-04, 1.1749e-03, 6.5039e-03, 3.9231e+06],\n",
      "       device='cuda:0')\n",
      "Tolerance after 13 iterations: 0.008363472297787666\n",
      "After IR: tensor(92094904., device='cuda:0')\n",
      "Iter 44/50 - Loss: 3377.555   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 9.2106e+07],\n",
      "       device='cuda:0')\n",
      "Tolerance after 15 iterations: 0.002984812716022134\n",
      "After IR: tensor(2.1579e+09, device='cuda:0')\n",
      "Iter 45/50 - Loss: -79117.164   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.1748e-04, 5.1490e-04, 8.0353e-03, 1.3382e-04, 1.5389e-04, 8.2845e-03,\n",
      "        1.7958e-04, 1.6051e-04, 1.1769e-03, 6.5037e-03, 2.1581e+09],\n",
      "       device='cuda:0')\n",
      "Tolerance after 21 iterations: 0.0003638629277702421\n",
      "After IR: tensor(5.0566e+10, device='cuda:0')\n",
      "Iter 46/50 - Loss: 1853989.875   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 5.0572e+10],\n",
      "       device='cuda:0')\n",
      "Tolerance after 21 iterations: 0.002153731882572174\n",
      "After IR: tensor(1.1849e+12, device='cuda:0')\n",
      "Iter 47/50 - Loss: -43444724.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.2524e-04, 5.1747e-04, 8.1474e-03, 1.3272e-04, 1.4510e-04, 8.2835e-03,\n",
      "        1.7958e-04, 1.6941e-04, 1.1772e-03, 6.5031e-03, 1.1851e+12],\n",
      "       device='cuda:0')\n",
      "Tolerance after 24 iterations: 0.004158767405897379\n",
      "After IR: tensor(2.7767e+13, device='cuda:0')\n",
      "Iter 48/50 - Loss: 1018045248.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.5551e+00, 1.3685e+01, 4.8294e+01, 9.9074e+00, 3.1124e+01, 1.2423e+01,\n",
      "        1.5060e+01, 2.4532e+01, 3.3476e+01, 1.6127e+01, 2.7770e+13],\n",
      "       device='cuda:0')\n",
      "Tolerance after 28 iterations: 0.0002069742331514135\n",
      "After IR: tensor(6.5066e+14, device='cuda:0')\n",
      "Iter 49/50 - Loss: -23855947776.000   lengthscale: 0.325   noise: 1.042\n",
      "Before IR: tensor([3.2369e-04, 5.2363e-04, 8.1474e-03, 1.3121e-04, 1.4267e-04, 8.2873e-03,\n",
      "        1.7958e-04, 1.6989e-04, 1.1791e-03, 6.5027e-03, 6.5073e+14],\n",
      "       device='cuda:0')\n",
      "Tolerance after 30 iterations: 0.004137684591114521\n",
      "After IR: tensor(1.5247e+16, device='cuda:0')\n",
      "Iter 50/50 - Loss: 559019130880.000   lengthscale: 0.325   noise: 1.042\n"
     ]
    }
   ],
   "source": [
    "training_iter = 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "with gpytorch.settings.skip_logdet_forward(), \\\n",
    "    gpytorch.settings.max_preconditioner_size(0), \\\n",
    "    gpytorch.settings.ir_solve(), \\\n",
    "    gpytorch.settings.cg_tolerance(1e-5), \\\n",
    "    gpytorch.settings.max_cg_iterations(len(train_y)), \\\n",
    "    gpytorch.settings.deterministic_probes(), \\\n",
    "    gpytorch.settings.num_trace_samples(10)\\\n",
    ":\n",
    "    \n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.base_kernel.lengthscale.item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions with the model\n",
    "\n",
    "In the next cell, we make predictions with the model. To do this, we simply put the model and likelihood in eval mode, and call both modules on the test data.\n",
    "\n",
    "Just as a user defined GP model returns a `MultivariateNormal` containing the prior mean and covariance from forward, a trained GP model in eval mode returns a `MultivariateNormal` containing the posterior mean and covariance. Thus, getting the predictive mean and variance, and then sampling functions from the GP at the given test points could be accomplished with calls like:\n",
    "\n",
    "```python\n",
    "f_preds = model(test_x)\n",
    "y_preds = likelihood(model(test_x))\n",
    "\n",
    "f_mean = f_preds.mean\n",
    "f_var = f_preds.variance\n",
    "f_covar = f_preds.covariance_matrix\n",
    "f_samples = f_preds.sample(sample_shape=torch.Size(1000,))\n",
    "```\n",
    "\n",
    "The `gpytorch.settings.fast_pred_var` context is not needed, but here we are giving a preview of using one of our cool features, getting faster predictive distributions using [LOVE](https://arxiv.org/abs/1803.06058)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(0, 1, 51, device=train_x.device)\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the model fit\n",
    "\n",
    "In the next cell, we plot the mean and confidence region of the Gaussian process model. The `confidence_region` method is a helper method that returns 2 standard deviations above and below the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.cpu().numpy(), train_y.cpu().numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.cpu().numpy(), observed_pred.mean.cpu().numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.cpu().numpy(), lower.cpu().numpy(), upper.cpu().numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
